{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of array: (388800, 300)\n",
      "Shape of array in windows: (1944, 200, 300)\n",
      "Shape of array after summing windows: (1944, 300)\n",
      "Fridge freezer12.csv\n",
      "(1944, 300)\n",
      "Shape of array: (388800, 300)\n",
      "Shape of array in windows: (1944, 200, 300)\n",
      "Shape of array after summing windows: (1944, 300)\n",
      "Oven42.csv\n",
      "(3888, 300)\n",
      "Shape of array: (388800, 300)\n",
      "Shape of array in windows: (1944, 200, 300)\n",
      "Shape of array after summing windows: (1944, 300)\n",
      "Microwave13.csv\n",
      "(5832, 300)\n",
      "Shape of array: (388800, 300)\n",
      "Shape of array in windows: (1944, 200, 300)\n",
      "Shape of array after summing windows: (1944, 300)\n",
      "Dish washer6.csv\n",
      "(7776, 300)\n",
      "(7776, 300)\n",
      "7776\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "from nilmtk import DataSet\n",
    "\n",
    "year = '2014'\n",
    "month = '2'\n",
    "filename = 'mains.csv'\n",
    "\n",
    "UK_DALE = '../../Datasets/UKDALE/ukdale.h5'\n",
    "END = \"{}-28-{}\".format(month, year)\n",
    "START = \"{}-1-{}\".format(month, year)\n",
    "train_building = 1\n",
    "filenames = ['Fridge freezer12.csv', 'Oven42.csv', 'Microwave13.csv', 'Dish washer6.csv']\n",
    "\n",
    "vectorized_appliances = None\n",
    "labels_of_vectorized_appliances = list()\n",
    "l = 0\n",
    "window = 200\n",
    "\n",
    "for filename in filenames:\n",
    "    FOLDER_PATH = '/media/christoforos/DATA/signal2vec/vectorized_sequences/{}/{}'.format(year, month)\n",
    "    df_vectorized = pd.read_csv(FOLDER_PATH + '/' + filename)\n",
    "    array = df_vectorized.values\n",
    "    print('Shape of array: {}'.format(array.shape))\n",
    "    array = np.reshape(array, (len(array)/window, window, 300))\n",
    "    sum_of_vectors = np.sum(array, axis=1)\n",
    "    print('Shape of array in windows: {}'.format(array.shape))\n",
    "    print('Shape of array after summing windows: {}'.format(sum_of_vectors.shape))\n",
    "\n",
    "    if vectorized_appliances is None:\n",
    "        vectorized_appliances = sum_of_vectors\n",
    "    else:\n",
    "        vectorized_appliances = np.concatenate((vectorized_appliances, sum_of_vectors))\n",
    "    labels_of_vectorized_appliances.extend([l for i in range(len(sum_of_vectors))]) \n",
    "    l += 1\n",
    "    print(filename)\n",
    "    print(vectorized_appliances.shape)\n",
    "\n",
    "print(vectorized_appliances.shape)\n",
    "print(len(labels_of_vectorized_appliances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of array: (432000, 300)\n",
      "Shape of array in windows: (2160, 200, 300)\n",
      "Shape of array after summing windows: (2160, 300)\n",
      "Fridge freezer12.csv\n",
      "(2160, 300)\n",
      "Shape of array: (432000, 300)\n",
      "Shape of array in windows: (2160, 200, 300)\n",
      "Shape of array after summing windows: (2160, 300)\n",
      "Oven42.csv\n",
      "(4320, 300)\n",
      "Shape of array: (432000, 300)\n",
      "Shape of array in windows: (2160, 200, 300)\n",
      "Shape of array after summing windows: (2160, 300)\n",
      "Microwave13.csv\n",
      "(6480, 300)\n",
      "Shape of array: (432000, 300)\n",
      "Shape of array in windows: (2160, 200, 300)\n",
      "Shape of array after summing windows: (2160, 300)\n",
      "Dish washer6.csv\n",
      "(8640, 300)\n",
      "(8640, 300)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "from nilmtk import DataSet\n",
    "\n",
    "year = '2014'\n",
    "month = '1'\n",
    "filename = 'mains.csv'\n",
    "\n",
    "UK_DALE = '../../Datasets/UKDALE/ukdale.h5'\n",
    "END = \"{}-30-{}\".format(month, year)\n",
    "START = \"{}-1-{}\".format(month, year)\n",
    "train_building = 1\n",
    "filenames = ['Fridge freezer12.csv', 'Oven42.csv', 'Microwave13.csv', 'Dish washer6.csv']\n",
    "\n",
    "vectorized_appliances_test = None\n",
    "labels_of_vectorized_appliances_test = list()\n",
    "l = 0\n",
    "for filename in filenames:\n",
    "    FOLDER_PATH = '/media/christoforos/DATA/signal2vec/vectorized_sequences/{}/{}'.format(year, month)\n",
    "    df_vectorized = pd.read_csv(FOLDER_PATH + '/' + filename)\n",
    "    array = df_vectorized.values\n",
    "    print('Shape of array: {}'.format(array.shape))\n",
    "    array = np.reshape(array, (len(array)/window, window, 300))\n",
    "    sum_of_vectors = np.sum(array, axis=1)\n",
    "    print('Shape of array in windows: {}'.format(array.shape))\n",
    "    print('Shape of array after summing windows: {}'.format(sum_of_vectors.shape))\n",
    "\n",
    "    if vectorized_appliances_test is None:\n",
    "        vectorized_appliances_test = sum_of_vectors\n",
    "    else:\n",
    "        vectorized_appliances_test = np.concatenate((vectorized_appliances_test, sum_of_vectors))\n",
    "    labels_of_vectorized_appliances_test.extend([l for i in range(len(sum_of_vectors))]) \n",
    "    l += 1\n",
    "    print(filename)\n",
    "    print(vectorized_appliances_test.shape)\n",
    "\n",
    "print(vectorized_appliances_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2, 7776]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-7548f6238164>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mvectorized_appliances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_of_vectorized_appliances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorized_appliances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_of_vectorized_appliances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorized_appliances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_of_vectorized_appliances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/christoforos/anaconda2/envs/nilm/lib/python2.7/site-packages/sklearn/utils/__init__.pyc\u001b[0m in \u001b[0;36mshuffle\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \"\"\"\n\u001b[1;32m    284\u001b[0m     \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/christoforos/anaconda2/envs/nilm/lib/python2.7/site-packages/sklearn/utils/__init__.pyc\u001b[0m in \u001b[0;36mresample\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m    202\u001b[0m                                                     n_samples))\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/christoforos/anaconda2/envs/nilm/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 7776]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier,\n",
    "                              AdaBoostClassifier)\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "print(len(vectorized_appliances))\n",
    "# clf = KNeighborsClassifier(n_neighbors=4)\n",
    "# clf = LogisticRegression(C=10)\n",
    "# clf = svm.SVC()\n",
    "clf = AdaBoostClassifier(n_estimators=500, learning_rate=1)\n",
    "\n",
    "vectorized_appliances, labels_of_vectorized_appliances = shuffle(vectorized_appliances, labels_of_vectorized_appliances, random_state=13)\n",
    "clf.fit(vectorized_appliances, labels_of_vectorized_appliances)\n",
    "\n",
    "pred = clf.predict(vectorized_appliances_test)\n",
    "f1 = f1_score(labels_of_vectorized_appliances_test, pred, average=None)\n",
    "print('F1 score: {}'.format(f1))\n",
    "f1 = f1_score(labels_of_vectorized_appliances_test, pred, average='micro')\n",
    "print('F1 micro: {}'.format(f1))\n",
    "f1 = f1_score(labels_of_vectorized_appliances_test, pred, average='macro')\n",
    "print('F1 macro: {}'.format(f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
